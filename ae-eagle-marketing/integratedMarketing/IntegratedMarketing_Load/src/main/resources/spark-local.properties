spark.enable.hive.support=true

#hive dev tier properties
hive.metastore.uris=thrift://...:9083
dfs.nameservices=testcluster
dfs.ha.namenodes.testcluster=nn1,nn2
dfs.namenode.rpc-address.testcluster.nn1=...:8020
dfs.namenode.rpc-address.testcluster.nn2=...:8020
spark.sql.warehouse.dir=default
dfs.client.failover.proxy.provider.testcluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

#sql dev tier properties
url=jdbc:sqlserver://...:1433
driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
user=...
password=...

#yarn properties
yarn.nodemanager.pmem-check-enabled=false
yarn.nodemanager.vmem-check-enabled=false